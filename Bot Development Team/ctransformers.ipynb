{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"D:\\LLM_models\\TheBloke\\Mistral-7B-OpenOrca-GGUF\\mistral-7b-openorca.Q5_0.gguf\", model_type=\"gpt2\", )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " change the world. But while AI's potential is enormous, it can only achieve as much as we let it, or rather, as much as we give it permission to do so. The question of whether AI should be autonomous, and how far that autonomy should extend, remains a matter of ongoing debate.\n",
      "\n",
      "In the realm of business, particularly where artificial intelligence is used in high-stakes decision making, this question becomes increasingly pertinent. The issue is not just about whether we trust AI to make decisions - but rather whether we should allow it to do so without human oversight, or with strict limitations.\n",
      "\n",
      "On one hand, autonomous AI could potentially improve efficiency and productivity by allowing tasks that can be automated to run uninterrupted. This means less work for humans, more time for creativity and strategy, and greater freedom in terms of how we allocate our resources.\n",
      "\n",
      "On the other hand, giving AI too much autonomy could lead to disastrous consequences if it makes poor decisions or is hacked by malicious actors. There's also the question of ethics: should AI be programmed to make moral choices, and who should be responsible for guiding its ethical framework?\n",
      "\n",
      "It would appear that striking a balance"
     ]
    }
   ],
   "source": [
    "for text in model(\"AI is going to\", stream=True):\n",
    "    print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? Iâ€™m not able to understand how to use the firebase-admin package in my code.\n"
     ]
    }
   ],
   "source": [
    "for text in model(\"Write me a python code for authentication using firebase with proper configuration\", stream=True):\n",
    "    print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'top_k':40,\n",
    "    'top_p':0.95,\n",
    "    'temperature':0.8,\n",
    "    'repetition_penalty':1.1,\n",
    "    'max_new_tokens':10000,\n",
    "    'seed':-1,\n",
    "    'stream':True,\n",
    "    'batch_size':512,\n",
    "    'threads':4,\n",
    "    'context_length':-1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import CTransformers\n",
    "\n",
    "llm = CTransformers(model='D:\\LLM_models\\TheBloke\\Mistral-7B-OpenOrca-GGUF\\mistral-7b-openorca.Q5_0.gguf', model_type='gpt2', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for text in llm('Write me a python code for authentication using firebase with proper configuration'):\n",
    "    print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "prompt_template = \"System:You are a helpful assistant, who has the capability to answer technology oriented questions only.\\n Question:{question}.\\n Answer: \"\n",
    "prompt = PromptTemplate(input_variables=[\"question\"], template=prompt_template)\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Langchain is an open-source Python library that enables developers and users to build applications with AI capabilities. It provides tools for working with large language models (LLMs), such as OpenAI's GPT-3, and other text-based data sources like databases or files. Langchain is designed for a wide range of use cases, including chatbots, summarization, question answering, text generation, and more.\\n\\nSome key features of Langchain include:\\n\\n1. Modular Architecture: Langchain is built with modular components that can be easily combined to create customized AI applications.\\n2. Framework-agnostic: It supports various frameworks like FastAPI, Flask, Django, and others for building production-ready web services.\\n3. Multiple Language Support: Langchain allows developers to use models trained in different languages to create AI applications.\\n4. Scalability: The library can easily integrate with tools that manage large datasets or scale up the computation power needed for more complex tasks.\\n5. Collaboration and Community: Langchain is an open-source project, which means anyone can contribute to its development and improve it over time.\\n\\nTo use Langchain in a Python project, you can install it using pip:\\n\\n```pip install langchain```\\n\\nOnce installed, you can follow the documentation on their GitHub repository or online tutorials to get started with building powerful AI applications using this library.\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run(\"Tell me about Langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (513) exceeded maximum context length (512).\n",
      "Number of tokens (514) exceeded maximum context length (512).\n",
      "Number of tokens (515) exceeded maximum context length (512).\n",
      "Number of tokens (516) exceeded maximum context length (512).\n",
      "Number of tokens (517) exceeded maximum context length (512).\n",
      "Number of tokens (518) exceeded maximum context length (512).\n",
      "Number of tokens (519) exceeded maximum context length (512).\n",
      "Number of tokens (520) exceeded maximum context length (512).\n",
      "Number of tokens (521) exceeded maximum context length (512).\n",
      "Number of tokens (522) exceeded maximum context length (512).\n",
      "Number of tokens (523) exceeded maximum context length (512).\n",
      "Number of tokens (524) exceeded maximum context length (512).\n",
      "Number of tokens (525) exceeded maximum context length (512).\n",
      "Number of tokens (526) exceeded maximum context length (512).\n",
      "Number of tokens (527) exceeded maximum context length (512).\n",
      "Number of tokens (528) exceeded maximum context length (512).\n",
      "Number of tokens (529) exceeded maximum context length (512).\n",
      "Number of tokens (530) exceeded maximum context length (512).\n",
      "Number of tokens (531) exceeded maximum context length (512).\n",
      "Number of tokens (532) exceeded maximum context length (512).\n",
      "Number of tokens (533) exceeded maximum context length (512).\n",
      "Number of tokens (534) exceeded maximum context length (512).\n",
      "Number of tokens (535) exceeded maximum context length (512).\n",
      "Number of tokens (536) exceeded maximum context length (512).\n",
      "Number of tokens (537) exceeded maximum context length (512).\n",
      "Number of tokens (538) exceeded maximum context length (512).\n",
      "Number of tokens (539) exceeded maximum context length (512).\n",
      "Number of tokens (540) exceeded maximum context length (512).\n",
      "Number of tokens (541) exceeded maximum context length (512).\n",
      "Number of tokens (542) exceeded maximum context length (512).\n",
      "Number of tokens (543) exceeded maximum context length (512).\n",
      "Number of tokens (544) exceeded maximum context length (512).\n",
      "Number of tokens (545) exceeded maximum context length (512).\n",
      "Number of tokens (546) exceeded maximum context length (512).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTo initialize Firebase Authentication in your Python code, you can use the Python library called \\'Firebase-Admin\\'. Here\\'s an example on how to do that:\\n\\n1. Firstly, install the \\'Firebase-Admin\\' library using pip:\\n```bash\\npip install firebase-admin\\n```\\n2. Next, create a service account key file (.json format) from your Firebase project\\'s settings. This is used for authenticating the Python script with Firebase Admin SDK.\\n3. Now, import the required libraries in your Python code:\\n```python\\nfrom firebase_admin import auth\\nimport firebase_admin\\n```\\n4. Initialize the Firebase Admin SDK using your service account key:\\n```python\\nservice_account = \\'path/to/your/service-account.json\\'\\nfirebase_admin.initialize_app(credentials=service_authentication.Credentials(service_account), options={\\'databaseURL\\': \\'https://<YOUR_PROJECT_ID>.firebaseio.com/\\'})\\n```\\nHere, replace \\'<YOUR_PROJECT_ID>\\' with your Firebase project ID.\\n5. Create a user by setting an email and password:\\n```python\\nuser = auth.create_user(email=\\'example@gmail.com\\', email_verified=True, password=\\'1234abcd\\')\\nprint(\"User created:\", user.uid)\\n```\\n6. Sign in a user with the given email and password:\\n```python\\nuser = auth.get_user_by_email(\\'example@gmail.com\\')\\nassert user is not None, \"User not found\"\\nuser = auth.sign_in_with_email_and_password(email=\\'example@gmail.com\\', password=\\'1234abcd\\')\\nprint(\"Sign in successful:\", user.uid)\\n```\\nRemember to change the email and password with your own credentials. \\n\\nThis code demonstrates how to initialize Firebase Authentication using Python and perform basic authentication tasks like creating a user and signing in an existing one. For more advanced features, refer to manage your can check out of FirebaseAuthentication or handling sign-like sending emails, you may require additional steps, please refer to work with Firebase.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run(\"Write me a python code to configure and perfrom authentication using firebase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`agent_scratchpad` should be a variable in prompt.input_variables. Did not find it, so adding it at the end.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import ZeroShotAgent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "conversational_buffer = ConversationBufferMemory(size=3)  # Adjust the size according to your needs\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain,conversational_buffer=conversational_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLangchain is an open-source library that helps developers build applications using AI and LLMs (Large Language Models), such as GPT-3 and GPT-4. It provides an accessible interface for working with these models by leveraging pre-built components like prompt templates, chainable functions, and data wrangling tools. Langchain enables developers to create powerful and efficient applications that utilize AI, without having to worry about the complexities of handling LLMs directly.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m The user wants information on 'Langchain'.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m The system responds with an explanation about Langchain.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m It should have 'Action:' instead of 'Answer:'.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action Input:' after 'Action:'\n",
      "Thought:\u001b[32;1m\u001b[1;3m The user wants to know more about Langchain.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m The system should provide more information about Langchain.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m This feedback helps improve the text format for better understanding.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m Adjustments need to be made for clarity and consistency in the conversation.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m The user is seeking more information on Langchain, a valuable tool for developers working with AI and LLMs.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m It's essential to provide clear and accurate details about the subject.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m This feedback highlights the need for appropriate formatting in AI text interactions.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (526) exceeded maximum context length (512).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m The user's request should be addressed with accurate and relevant information.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (527) exceeded maximum context length (512).\n",
      "Number of tokens (528) exceeded maximum context length (512).\n",
      "Number of tokens (529) exceeded maximum context length (512).\n",
      "Number of tokens (530) exceeded maximum context length (512).\n",
      "Number of tokens (531) exceeded maximum context length (512).\n",
      "Number of tokens (532) exceeded maximum context length (512).\n",
      "Number of tokens (533) exceeded maximum context length (512).\n",
      "Number of tokens (534) exceeded maximum context length (512).\n",
      "Number of tokens (535) exceeded maximum context length (512).\n",
      "Number of tokens (536) exceeded maximum context length (512).\n",
      "Number of tokens (537) exceeded maximum context length (512).\n",
      "Number of tokens (538) exceeded maximum context length (512).\n",
      "Number of tokens (539) exceeded maximum context length (512).\n",
      "Number of tokens (540) exceeded maximum context length (512).\n",
      "Number of tokens (541) exceeded maximum context length (512).\n",
      "Number of tokens (542) exceeded maximum context length (512).\n",
      "Number of tokens (543) exceeded maximum context length (512).\n",
      "Number of tokens (544) exceeded maximum context length (512).\n",
      "Number of tokens (545) exceeded maximum context length (512).\n",
      "Number of tokens (546) exceeded maximum context length (512).\n",
      "Number of tokens (547) exceeded maximum context length (512).\n",
      "Number of tokens (548) exceeded maximum context length (512).\n",
      "Number of tokens (549) exceeded maximum context length (512).\n",
      "Number of tokens (550) exceeded maximum context length (512).\n",
      "Number of tokens (551) exceeded maximum context length (512).\n",
      "Number of tokens (552) exceeded maximum context length (512).\n",
      "Number of tokens (584) exceeded maximum context length (512).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m This feedback has notations: It'\n",
      "\n",
      "```\n",
      "Action: The user wants a1: To Action Input:\u001b[0m\n",
      "Observation: The user wants a1: To is not a valid tool, try one of [duckduckgo_search].\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (585) exceeded maximum context length (512).\n",
      "Number of tokens (586) exceeded maximum context length (512).\n",
      "Number of tokens (587) exceeded maximum context length (512).\n",
      "Number of tokens (588) exceeded maximum context length (512).\n",
      "Number of tokens (589) exceeded maximum context length (512).\n",
      "Number of tokens (590) exceeded maximum context length (512).\n",
      "Number of tokens (591) exceeded maximum context length (512).\n",
      "Number of tokens (592) exceeded maximum context length (512).\n",
      "Number of tokens (593) exceeded maximum context length (512).\n",
      "Number of tokens (594) exceeded maximum context length (512).\n",
      "Number of tokens (595) exceeded maximum context length (512).\n",
      "Number of tokens (596) exceeded maximum context length (512).\n",
      "Number of tokens (597) exceeded maximum context length (512).\n",
      "Number of tokens (598) exceeded maximum context length (512).\n",
      "Number of tokens (599) exceeded maximum context length (512).\n",
      "Number of tokens (600) exceeded maximum context length (512).\n",
      "Number of tokens (601) exceeded maximum context length (512).\n",
      "Number of tokens (602) exceeded maximum context length (512).\n",
      "Number of tokens (603) exceeded maximum context length (512).\n",
      "Number of tokens (604) exceeded maximum context length (512).\n",
      "Number of tokens (605) exceeded maximum context length (512).\n",
      "Number of tokens (606) exceeded maximum context length (512).\n",
      "Number of tokens (607) exceeded maximum context length (512).\n",
      "Number of tokens (608) exceeded maximum context length (512).\n",
      "Number of tokens (609) exceeded maximum context length (512).\n",
      "Number of tokens (629) exceeded maximum context length (512).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m The user: Langchain: The system response\n",
      " Thing: The user provides additional details and Action: It should be\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action Input:' after 'Action:'\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (630) exceeded maximum context length (512).\n",
      "Number of tokens (631) exceeded maximum context length (512).\n",
      "Number of tokens (632) exceeded maximum context length (512).\n",
      "Number of tokens (633) exceeded maximum context length (512).\n",
      "Number of tokens (634) exceeded maximum context length (512).\n",
      "Number of tokens (635) exceeded maximum context length (512).\n",
      "Number of tokens (636) exceeded maximum context length (512).\n",
      "Number of tokens (637) exceeded maximum context length (512).\n",
      "Number of tokens (638) exceeded maximum context length (512).\n",
      "Number of tokens (639) exceeded maximum context length (512).\n",
      "Number of tokens (640) exceeded maximum context length (512).\n",
      "Number of tokens (641) exceeded maximum context length (512).\n",
      "Number of tokens (642) exceeded maximum context length (512).\n",
      "Number of tokens (643) exceeded maximum context length (512).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m The user wants a2: The user: The user wants to\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Chatbot\\gpt\\gpt\\ctransformers.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Chatbot/gpt/gpt/ctransformers.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magents\u001b[39;00m \u001b[39mimport\u001b[39;00m AgentExecutor\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Chatbot/gpt/gpt/ctransformers.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m agent_executor \u001b[39m=\u001b[39m AgentExecutor\u001b[39m.\u001b[39mfrom_agent_and_tools(agent\u001b[39m=\u001b[39magent,tools\u001b[39m=\u001b[39m[search_tool], verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,llm_chain\u001b[39m=\u001b[39mllm_chain, handle_parsing_errors\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Chatbot/gpt/gpt/ctransformers.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m result \u001b[39m=\u001b[39m agent_executor\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mTell me about Langchain\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Chatbot/gpt/gpt/ctransformers.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m result\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "#\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent,tools=[search_tool], verbose=True,llm_chain=llm_chain, handle_parsing_errors=True)\n",
    "result = agent_executor.run(\"Tell me about Langchain\")['text']\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"In above, we get the error because, we didn't define action sequence for the agent, thought and scratchpad. If things are added appropriately, then we can get the proper output.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
